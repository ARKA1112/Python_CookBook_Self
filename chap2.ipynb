{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting String on Any of Multiple Delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem: YOu need to split a string into fields, but the delimiters arent consistent throughout the string\n",
    "\n",
    "\n",
    "\n",
    "line = 'asdf fjdk; afed, fjek,asdf,foo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'[;,\\s]\\s*',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = re.split(r'(;|,|\\s)\\s*', line)\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = fields[::2]\n",
    "delimiters = fields[1::2] + ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ';', ',', ',', ',', '']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdf fjdk;afed,fjek,asdf,foo'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reform the line using the same delimiters\n",
    "\n",
    "''.join(v+d for v,d in zip(values, delimiters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you dont want the separator characters in the result but still need to use parentheses to group parts of the regular expression pattern, make sure you use a noncapture group, specified as (?:...)\n",
    "\n",
    "\n",
    "\n",
    "re.split(r'(?:,|;|\\s)\\s*', line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching Text at the Start or End of a String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem you need to check the start or end of a strin gfo r secific text patterns such as fileneame extensions, URL schems, and so on.\n",
    "\n",
    "\n",
    "filename = 'spam.txt'\n",
    "filename.endswith('.txt')\n",
    "\n",
    "\n",
    "url = 'http://www.python.org'\n",
    "url.startswith('http')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git', 'README.md', 'chap1.ipynb', '.vscode', '.gitignore', 'chap2.ipynb']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chap1.ipynb', 'chap2.ipynb']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in filenames if name.endswith('.ipynb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(name.endswith('.py') for name in filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "def read_data(name):\n",
    "    if name.startswith(('http:', 'https:','ftp:')):\n",
    "        return urlopen(name).read()\n",
    "    else:\n",
    "        with open(name) as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = ['http', 'ftp']\n",
    "url = 'http://www.python.org'\n",
    "url.startswith(tuple(choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='http:'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One might be inclined to use regular expressions as an alternative. FOr examle\n",
    "\n",
    "import re\n",
    "url = 'http://www.python.org'\n",
    "re.match('https:|http:|frp:', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(5, 10), match='class'>\n",
      "None\n",
      "(0, 5)\n",
      "None\n",
      "(0, 5)\n",
      "(2, 7)\n",
      "(0, 32)\n",
      "<html><head><title>Title</title>\n",
      "<html><head><title>Title</title>\n"
     ]
    }
   ],
   "source": [
    "#from https://docs.python.org/3/howto/regex.html\n",
    "import re\n",
    "p = re.compile(r'\\bclass\\b')\n",
    "print(p.search(\"Fine class\"))  #\\b is a word limiter and matches only if there is the word\n",
    "print(p.search(\"subclass\"))\n",
    "\n",
    "#Also if r was not used then \\b would mean backspace character\n",
    "\n",
    "#Groups\n",
    "\n",
    "p = re.compile('(ab)*') #matches if only ab pattern is there\n",
    "\n",
    "p.match('abababab').span()  #8 patterns found\n",
    "\n",
    "p = re.compile('(a)b')\n",
    "m = p.match('ab')\n",
    "m.group()\n",
    "\n",
    "m.group(0)\n",
    "\n",
    "\n",
    "#subgroups are numberred form left to right from 1 upward. Groups can be nested to determine the number just count he opening parenthesis characters going from left to right\n",
    "\n",
    "\n",
    "p = re.compile('(a(b)c)d') #groups are assigned based on the brackets\n",
    "\n",
    "m = p.match('abcd')\n",
    "m.group(0)\n",
    "m.group(1)\n",
    "m.group(2)   #three gruops will be there\n",
    "\n",
    "\n",
    "#incase we want to know the groups\n",
    "\n",
    "m.group(0,1,2)\n",
    "#also\n",
    "m.groups()\n",
    "\n",
    "#For example the following Re detects dobled words in a stirng\n",
    "\n",
    "p = re.compile(r'\\b(\\w+)\\s+\\1\\b')\n",
    "p.search('Paris in the the spring').group()\n",
    "\n",
    "\n",
    "m = re.match(\"([abc])+\", \"abc\")\n",
    "m.groups()\n",
    "\n",
    "m = re.match(\"(?:[abc])+\", \"abc\")\n",
    "m.groups()\n",
    "\n",
    "#Search for a specific word\n",
    "\n",
    "\n",
    "p = re.compile(r'(?P<word>\\b\\w+\\b)')\n",
    "m = p.search('((( Lots of punctuation)))')\n",
    "m.group('word')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Additonally, you can retrieve named groups as a dictionary with groupdict()\n",
    "\n",
    "\n",
    "m.groupdict()   #shows the group dictionary\n",
    "\n",
    "\n",
    "p = re.compile(r'\\b(?P<word>\\w+)\\s+(?P=word)\\b')\n",
    "p.search('Paris in the the spring').group()\n",
    "\n",
    "\n",
    "\n",
    "p = re.compile(r'\\W+')\n",
    "\n",
    "p.split('This is a test, short and sweet, of split().')\n",
    "\n",
    "\n",
    "\n",
    "#if we specify maxsplit\n",
    "\n",
    "p.split('This is a test, short and sweet, of split().', 3)\n",
    "\n",
    "\n",
    "\n",
    "#incase you also need to separate the delimiters\n",
    "\n",
    "p = re.compile(r'\\W+')\n",
    "p2 = re.compile(r'(\\W+)') #group by words\n",
    "\n",
    "p.split(\"This ... is a test\")   #ignores symbols\n",
    "\n",
    "p2.split(\"This ... is a tes\")  #also takes on white spaces\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "re.split(r'[\\W+]', 'Words, WOrds, WOrds')  #takes on whitespaces only\n",
    "\n",
    "re.split(r'([\\W]+)', 'Words,words,words')\n",
    "\n",
    "\n",
    "#Search and replace\n",
    "\n",
    "p = re.compile('(blue|white|red)')\n",
    "p.sub('colour', 'blue socks and red shoes')\n",
    "p.sub('color', 'blue socks and red shoes', count=1)  #only one occurence replaced\n",
    "\n",
    "\n",
    "\n",
    "#subn() works the same but returns a 2 tuple containing the new string value and the number of replacements that were performed\n",
    "\n",
    "p =  re.compile('(blue|white|red)')\n",
    "p.subn('color', 'blue socks and red shoes')\n",
    "\n",
    "\n",
    "\n",
    "#Empty matches are replaced only when thery are not adjacent to a previous empty match\n",
    "\n",
    "p  = re.compile('x*')\n",
    "p.sub('-','abxd')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#The following example the replacement functiontranslates decimals into hexadecimal\n",
    "\n",
    "def hexrepl(match):\n",
    "    \"return the hex string for a decimal number\"\n",
    "    value = int(match.group())\n",
    "    return hex(value)\n",
    "\n",
    "p = re.compile(r'\\d+')\n",
    "p.sub(hexrepl, 'Call 6478 for printing, 987 for user code')\n",
    "\n",
    "\n",
    "\n",
    "#common problems\n",
    "\n",
    "#match() function only checks if the re matches at the beginning of the stirn gwhile search() will scan forward through the string for a match which will start at 0;\n",
    "\n",
    "\n",
    "print(re.match('super', 'superstition').span())  #returns\n",
    "\n",
    "print(re.match('super', 'insuperable'))\n",
    "\n",
    "\n",
    "#on the other hand search() will sacn forward through the stirn greporting the first match if finds\n",
    "\n",
    "print(re.search('super','superstition').span())\n",
    "print(re.search('super', 'insuperable').span())\n",
    "\n",
    "\n",
    "\n",
    "#Greedy versus NonGreedy\n",
    "\n",
    "\n",
    "s = '<html><head><title>Title</title>'\n",
    "len(s)\n",
    "print(re.match('<.*>', s).span())\n",
    "print(re.match('<.*>',s).group())\n",
    "\n",
    "\n",
    "print(re.match('<.*>',s).group())\n",
    "\n",
    "\n",
    "#using re.VERBOSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http:'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Continuing from the cookbook\n",
    "\n",
    "import re\n",
    "url = 'http://www.python.org'\n",
    "re.match(r'http:|https:|ftp:',url).group()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching Strings Using Shell Wildcard patterns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fnmatch import fnmatch, fnmatchcase\n",
    "\n",
    "fnmatch('foo.txt','*.txt')\n",
    "fnmatch('foo.txt','?oo.txt')\n",
    "fnmatch('Dat45.csv','Dat[0-9]*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in names if fnmatch(name, 'Dat*.csv')]\n",
    "\n",
    "\n",
    "#Also the case sensitivity is base on the system's underlying filesystem\n",
    "\n",
    "fnmatch('foo.txt','*.TXT')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#if distinction matters then use fnmatchcase\n",
    "\n",
    "fnmatchcase('foo.txt','*.TXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = [\n",
    "'5412 N CLARK ST',\n",
    "'1060 W ADDISON ST',\n",
    "'1039 W GRANVILLE AVE',\n",
    "'2122 N CLARK ST',\n",
    "'4802 N BROADWAY',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1060 W ADDISON ST', '1039 W GRANVILLE AVE']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fnmatch import fnmatchcase\n",
    "\n",
    "[addr for addr in addresses if fnmatchcase(addr, '* ST')]\n",
    "\n",
    "[addr for addr in addresses if fnmatchcase(addr, '10[0-9][0-9] W*')]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching and searching for text patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text == 'yeah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.startswith('yeah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.find('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "#for more complilcated matchinguser regular expressions and the re module. To illstrate the basic mechanics of usin regular expressions\n",
    "\n",
    "\n",
    "text1 = '11/27/2022'\n",
    "text2 = 'Nov 27, 2012'\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "if re.match(r'\\d+/\\d+/\\d+', text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "#if you are going to perform a lot of matches using the same pattern it ussually pays to precompile the regular expression pattern into a pattern object firest. \n",
    "\n",
    "\n",
    "datapat = re.compile(r'\\d+/\\d+/\\d+')\n",
    "if datapat.match(text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('nein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "#datapat.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can also group it \n",
    "import re\n",
    "\n",
    "datepat=  re.compile(r'(\\d+)/(\\d+)/(\\d+)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = datepat.match('11/27/2022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'11'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/27/2012\n",
      "3/13/2013\n"
     ]
    }
   ],
   "source": [
    "for month,day,year in datepat.findall(text):\n",
    "    print(f'{month}/{day}/{year}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('11', '27', '2012')\n",
      "('3', '13', '2013')\n"
     ]
    }
   ],
   "source": [
    "#if you want o find matches iteratively use the finditer() method instead.\n",
    "\n",
    "\n",
    "for m in datepat.finditer(text):\n",
    "    print(m.groups())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching and Replacing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yep, but no, but yep, but no, but yep'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#You want to search for and replace a text pattern in a string\n",
    "\n",
    "text1 = 'yeah, but no, but yeah, but no, but yeah'\n",
    "text1.replace('yeah', 'yep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 2012-11-27. PyCon starts 2013-3-13.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'(\\d+)/(\\d+)/(\\d+)', r'\\3-\\1-\\2', text)\n",
    "\n",
    "#format the date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from calendar import month_abbr\n",
    "def change_date(m):\n",
    "    mon_name = month_abbr[int(m.group(1))]\n",
    "    return '{} {} {}'.format(m.group(2), mon_name, m.group(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Today is 27 Nov 2012. PyCon starts 13 Mar 2013.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datepat.sub(change_date,text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2013'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(34, 43), match='3/13/2013'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching and Replacing Case Insensitive Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PYTHON', 'python', 'Python']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text2 = 'UPPER PYTHON, lower python, Mixed Python'\n",
    "re.findall('python', text2, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'UPPER snake, lower snake, Mixed snake'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('python','snake',text2,flags=re.IGNORECASE)\n",
    "\n",
    "#also the case doesnt match that of the replaced text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#so we formulate a function\n",
    "\n",
    "def matchcase(word):\n",
    "    def replace(m):\n",
    "        text = m.group()\n",
    "        if text.isupper():\n",
    "            return word.upper()\n",
    "\n",
    "        elif text.islower():\n",
    "            return word.lower()\n",
    "\n",
    "        elif text[0].isupper():\n",
    "            return word.capitalize()\n",
    "        else:\n",
    "            return word\n",
    "    return replace\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Computer says \"no.\" Phone says \"yes.\"'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('python', matchcase('snake'), text2, flags=re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3/13/2013'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.group()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying a Regular Expression for the shortest match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no.\" Phone says \"yes.']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_pat = re.compile(r'\\\"(.*)\\\"')\n",
    "text1  =  'Computer says \"no.\"'\n",
    "str_pat.findall(text1)\n",
    "\n",
    "text2 = 'Computer says \"no.\" Phone says \"yes.\"'\n",
    "str_pat.findall(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['no.', 'yes.']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str_pat=  re.compile(r'\\\"(.*?)\\\"')  #The question mark makes it nongreedy\n",
    "\n",
    "str_pat.findall(text2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.8. Writing a Regular Expression for Multiline Patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "comment = re.compile(r'/\\*(.*?)\\*/')\n",
    "text1 = '/* this is a comment */'\n",
    "text2 = \"\"\"/* this is a \n",
    "multiline comment */\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment.findall(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to fix the problem\n",
    "\n",
    "comment = re.compile(r'/\\*((?:.|\\n)*?)\\*/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' this is a \\nmultiline comment ']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comment.findall(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' this is a \\nmultiline comment ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#alson using dotall\n",
    "\n",
    "comment = re.compile(r'/\\*(.*?)\\*/', re.DOTALL)\n",
    "comment.findall(text2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.9. Normalizing Unicode Text to a Standard\n",
    "Representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 15)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'Spicy Jalape\\u00f1o'\n",
    "s2 = 'Spicy Jalapen\\u0303o'\n",
    "\n",
    "s1, s2\n",
    "\n",
    "s1==s2\n",
    "len(s1),len(s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "t1 = unicodedata.normalize('NFC',s1)\n",
    "t2 = unicodedata.normalize('NFC',s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Spicy Jalape\\xf1o'\n"
     ]
    }
   ],
   "source": [
    "print(ascii(t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = unicodedata.normalize('NFD', s1)\n",
    "t4 = unicodedata.normalize('NFD', s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spicy Jalapeño'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NFC means the characters should be fully composed (ie use a single code point if possible)\n",
    "\n",
    "#NFD means the characters should be fully decomposed with the use of combining characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ﬁ'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '\\ufb01'  #A single character\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fi'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unicodedata.normalize('NFKD',s)   #The combined letters are broken apart here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spicy Jalapeno'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = unicodedata.normalize('NFD',s1)\n",
    "''.join(c for c in t1 if not unicodedata.combining(c))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.10. Working with Unicode Characters in Regular\n",
    "Expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='١٢٣'>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "num = re.compile('\\d+')\n",
    "\n",
    "#ASCII digits\n",
    "\n",
    "num.match('123')\n",
    "\n",
    "\n",
    "\n",
    "#Arabic digits\n",
    "\n",
    "num.match('\\u0661\\u0662\\u0663')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic= re.compile('[\\u0600-\\u06ff\\u0750-\\u077f\\u08a0-\\u08ff]+')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[\\u0600-ۿݐ-ݿࢠ-ࣿ]+', re.UNICODE)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arabic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat = re.compile('stra\\u00dfe', re.IGNORECASE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'straße'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 6), match='straße'>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pat.match(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pat.match(s.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'STRASSE'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.upper()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.11. Stripping Unwanted Characters from Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '   Hello World    \\n'\n",
    "s.strip() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World    \\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.lstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   Hello World'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'---------hello'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Character stripping\n",
    "\n",
    "t = '---------hello======'\n",
    "t.lstrip('-')\n",
    "t.rstrip('=')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.strip('-=') #strips both"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Be aware that stripping does not apply to any text in the middle of a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello            world'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '  hello            world   \\n'\n",
    "s = s.strip()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello            world'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.replace(' ',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello world'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using re\n",
    "\n",
    "import re\n",
    "re.sub(r'\\s+',' ',s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2.12. Sanitizing and Cleaning Up Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem : Someone has entered “pýtĥöñ” into a form on your we page and youd like to clean it up somehow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'pýtĥöñ\\fis\\tawesome\\r\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pýtĥöñ\\x0cis\\tawesome\\r\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "remap = {ord('\\t') : ' ', ord('\\f') : ' ', ord('\\r') : None}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = s.translate(remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pýtĥöñ is awesome\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pýtĥöñ is awesome\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unicodedata\n",
    "import sys\n",
    "cmb_chrs = dict.fromkeys(c for c in range(sys.maxunicode) if unicodedata.combining(chr(c)))\n",
    "\n",
    "b = unicodedata.normalize('NFD', a)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is awesome\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.translate(cmb_chrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As another example here is a translation table that maps all Unicode deciamal digit characters to their equivalent in ASCII"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "digitmap = {c : ord('0') + unicodedata.digit(chr(c)) for c in range(sys.maxunicode) if unicodedata.category(chr(c)) == 'Nd'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "660"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arabic digits\n",
    "\n",
    "x = '\\u0661\\u0662\\u0663'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.translate(digitmap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pýtĥöñ is awesome\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python is awesome\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = unicodedata.normalize('NFD',a)\n",
    "b.encode('ascii', 'ignore').decode('ascii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"hi iz right\"\n",
    "ch = {ord('i'):'e', ord('z'):'s'}\n",
    "a = s.translate(ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_spaces(s):\n",
    "    s = s.replace('\\r', '')\n",
    "    s = s.replace('\\t', ' ')\n",
    "    s = s.replace('\\f', ' ')\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pýtĥöñ\\x0cis\\tawesome\\r\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = clean_spaces(s)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aligning Text Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to format text with some sort of alignnment applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_________Hello World_________'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Hello World'\n",
    "text.ljust(20),text.rjust(20)\n",
    "text.center(29,'_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World*********'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format(text,'>20')\n",
    "format(text, '<20')\n",
    "format(text, '*<20')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'     Hello      World'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'{:>10s} {:>10s}'.format('Hello','World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The format method also works with integers and not only strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Hello              '"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Older code\n",
    "\n",
    "'%-20s' % ' Hello'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining and Concatenating Stirngs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"This is a test script\"\n",
    "sl = s.split(' ') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is a test script'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Thisisatestscript'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(sl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'Hello ' 'World'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello World'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To lookout for\n",
    "\n",
    "#Better method to concatenate multiple strings with a common separator\n",
    "\n",
    "print( a, b, c, sep = ':')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joining multiple strings without extracting them directly to the memory first\n",
    "\n",
    "def sample():\n",
    "    yield \"New York\"\n",
    "    yield \"Boston\"\n",
    "    yield \"Chicago\"\n",
    "    yield \"Milwaukee\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'New York Boston Chicago Milwaukee'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Also another way to do this is\n",
    "\n",
    "for i in sample():\n",
    "    '.'.join(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('textfile.txt','w+') as f:\n",
    "    for i in sample():\n",
    "        f.write(i+'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "with open('textfile.txt','w+') as f:\n",
    "    for i in enumerate(sample(), start=1):\n",
    "        i = str(i)\n",
    "        i = re.sub(r\"[()]\",\"\",i)\n",
    "        f.write(str(i)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine(source, maxsize):\n",
    "    parts = []\n",
    "    size = 0\n",
    "    for i in source:\n",
    "        parts.append(i)\n",
    "        size+= len(i)\n",
    "        if size > maxsize:\n",
    "            yield ' '.join(parts)\n",
    "            parts = []\n",
    "            size = 0\n",
    "    yield ' '.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('textfile.txt', 'w+')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in combine(sample(), 11):\n",
    "    f.write(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpolating Variables in Strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guidp has 37 messages.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = '{name} has {n} messages.'\n",
    "s.format(name = 'Guidp',n = '37')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Template' object has no attribute 'format_map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [69], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m name \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mGuido\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m      2\u001b[0m n \u001b[39m=\u001b[39m \u001b[39m37\u001b[39m\n\u001b[0;32m----> 4\u001b[0m s\u001b[39m.\u001b[39;49mformat_map(\u001b[39mvars\u001b[39m())\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Template' object has no attribute 'format_map'"
     ]
    }
   ],
   "source": [
    "name = 'Guido'\n",
    "n = 37\n",
    "\n",
    "s.format_map(vars())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Info:\n",
    "    def __init__(self, name, n):\n",
    "        self.name = name\n",
    "        self.n = n\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return '{}{}'.format(self.__class__.__name__,(self.name, self.n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Info('Guido', 37)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = Info('Guido',37)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.format_map(vars(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#One downside fo format and format_map is that they do not deal gracefully with missing values. \n",
    "\n",
    "#s.format(name='Guido') #Fails\n",
    "\n",
    "class Safesub(dict):\n",
    "    def __missing__(self, key):\n",
    "        return '{' + key + '}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "del n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has {n} messages.'"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.format_map(Safesub(vars()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you find yourself frequently performing thest steps in your code you could hide the variable substitution process behind a small utility function that employs a so called \"frame hack\". For example\n",
    "\n",
    "import sys\n",
    "\n",
    "def sub(text):\n",
    "    return text.format_map(Safesub(sys._getframe(1).f_locals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'self': <ipykernel.zmqshell.ZMQInteractiveShell at 0x7fd74d03a850>,\n",
       " 'code_obj': <code object <module> at 0x7fd72aa59b30, file \"/tmp/ipykernel_6600/1286078319.py\", line 1>,\n",
       " 'result': <ExecutionResult object at 7fd72a988310, execution_count=67 error_before_exec=None error_in_exec=None info=<ExecutionInfo object at 7fd72a993950, raw_cell=\"sys._getframe(1).f_locals\" store_history=True silent=False shell_futures=True cell_id=vscode-notebook-cell:/home/susearc/Documents/github/Python_CookBook_Self/chap2.ipynb#Y265sZmlsZQ%3D%3D> result=None>,\n",
       " 'async_': False,\n",
       " '__tracebackhide__': '__ipython_bottom__',\n",
       " 'old_excepthook': <bound method IPKernelApp.excepthook of <ipykernel.kernelapp.IPKernelApp object at 0x7fd74fed7610>>,\n",
       " 'outflag': True}"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys._getframe(1).f_locals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Guido has 37 messages'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Alternative string method is also inplace\n",
    "\n",
    "import string\n",
    "name = 'Guido'\n",
    "n = 37\n",
    "s = string.Template('$name has $n messages')\n",
    "s.substitute(vars())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformatting Text to a Fixed Number of Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Look into my eyes, look into my eyes, the eyes, the eyes, \\\n",
    "the eyes, not around the eyes, don't look around the eyes, \\\n",
    "look into my eyes, you're under.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Look into my\n",
      "eyes, look into my\n",
      "eyes, the eyes, the\n",
      "eyes, the eyes, not\n",
      "around the eyes,\n",
      "don't look around\n",
      "the eyes, look into\n",
      "my eyes, you're\n",
      "under.\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "print(textwrap.fill(s,20,initial_indent='----'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Handling HTML and XML Entities in Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You want to replace HTML or XML entities such as &entity or &#code; with their corresponding text. Alternatively you need to produce text but escape certain characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Elements are writtern as \"<tag>text</tag>\".'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elements are writtern as \"&lt;tag&gt;text&lt;/tag&gt;\".\n"
     ]
    }
   ],
   "source": [
    "import html\n",
    "print(html.escape(s, quote=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you are trying to emit text as ASCII and want to embed character cod eentitites for non Ascii charactersw you can use the errors = 'xmlcharrefreplace' argument to various I/O related functions to do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'Spicy Jalape&#241;o'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = 'Spicy Jalapeño'\n",
    "s.encode('ascii', errors='xmlcharrefreplace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'Spicy &quot;Jalape&#241;o&quot.'\n",
    "from html.parser import HTMLParser\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'foo = 23 + 42 * 10'\n",
    "#The tokenized text will be like this\n",
    "tokens = [('NAME', 'foo'), ('EQ','='), ('NUM', '23'),('PLUS','+'),('NUM', '42'), ('TIMES', '*'),('NUM', '10')]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do this we can do the following\n",
    "\n",
    "import re\n",
    "NAME = r'(?P<NAME>[a-zA-Z_][a-zA-z_0-9]*)'\n",
    "EQ = r'(?P<EQ>=)'\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "WS = r'(?P<WS>\\s+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_pat = re.compile('|'.join([NAME, EQ, NUM, PLUS, TIMES, WS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'(?P<NAME>[a-zA-Z_][a-zA-z_0-9]*)|(?P<EQ>=)|(?P<NUM>\\d+)|(?P<PLUS>\\+)|(?P<TIMES>\\*)|(?P<WS>\\s+)',\n",
       "           re.UNICODE)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='foo'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scanner = master_pat.scanner('foo = 42')\n",
    "scanner.match()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NAME'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.lastgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_.group()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "Token = namedtuple('Token',['type','value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_tokens(pat, text):\n",
    "    scanner = pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        yield Token(m.lastgroup, m.group())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token(type='NAME', value='foo')\n",
      "Token(type='EQ', value='=')\n",
      "Token(type='NUM', value='42')\n"
     ]
    }
   ],
   "source": [
    "for tok in generate_tokens(master_pat, 'foo=42'):\n",
    "    print(tok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The order of teh tokes in the master regular expression also matters. WHen matching re tries to match patterns in the order specified. Thus if a pattern happens to be a substring of a longer pattern. you need to make sure the longer pattern goes first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "LT = r'(?P<LT><)'\n",
    "LE = r'(?P<LE><=)'\n",
    "EQ = r'(?P<EQ>=)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_pat = re.compile('|'.join([LT, LE, EQ]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Last but not least you need to wathc out for patterns that form substrings. For example suppose you have two patterns like this:\n",
    "\n",
    "PRINT = r'(P<PRINT>print)'\n",
    "NAME = r'(P<NAME>[a-zA-Z_][a-zA-Z_0-9]*)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_pat  =re.compile('|'.join([PRINT, NAME]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tok in generate_tokens(master_pat,'printer'):\n",
    "    print(tok)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You need to parse text according to a set of grammar rules and perform actions or build an abstract syntax tree representing the input. The grammar is small so youd prefer to just write the parser yourself as opposed to using some kind of framework."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Writing a Simple Recursive Descent Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import collections\n",
    "\n",
    "# Token specification\n",
    "NUM = r'(?P<NUM>\\d+)'\n",
    "PLUS = r'(?P<PLUS>\\+)'\n",
    "MINUS = r'(?P<MINUS>-)'\n",
    "TIMES = r'(?P<TIMES>\\*)'\n",
    "DIVIDE = r'(?P<DIVIDE>/)'\n",
    "LPAREN = r'(?P<LPAREN>\\()'\n",
    "RPAREN = r'(?P<RPAREN>\\))'\n",
    "WS = r'(?P<WS>\\s+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_pat = re.compile('|'.join([NUM, PLUS, MINUS, TIMES,DIVIDE,LPAREN, RPAREN, WS]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'(?P<NUM>\\d+)|(?P<PLUS>\\+)|(?P<MINUS>-)|(?P<TIMES>\\*)|(?P<DIVIDE>/)|(?P<LPAREN>\\()|(?P<RPAREN>\\))|(?P<WS>\\s+)',\n",
       "           re.UNICODE)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Token\n",
    "Token = collections.namedtuple('Token',['type', 'value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_token(text):\n",
    "    scanner = master_pat.scanner(text)\n",
    "    for m in iter(scanner.match, None):\n",
    "        tok = Token(m.lastgruop, m.group())\n",
    "        if tok.type != 'WS':\n",
    "            yield tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[b'FOO', b'BAR', b'SPAM']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = b'FOO:BAR,SPAM'\n",
    "import re\n",
    "#re.split('[:,]',data) #incorrect method\n",
    "re.split(b'[:,]',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a UTF-8 filename\n",
    "\n",
    "with open('jalape\\xf1o.txt','w+') as f:\n",
    "    f.write('spicy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git',\n",
       " 'README.md',\n",
       " 'chap1.ipynb',\n",
       " '.vscode',\n",
       " '.gitignore',\n",
       " 'chap2.ipynb',\n",
       " 'textfile.txt',\n",
       " 'jalapeño.txt']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#getting a directory listing\n",
    "\n",
    "import os\n",
    "os.listdir(b'.') #in bytecode format\n",
    "os.listdir('.') #in string format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-pypy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f5533fd6924202fd88ccc6d81a9f253a530b6dfb71af0b09e2f01180b11fc04"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
