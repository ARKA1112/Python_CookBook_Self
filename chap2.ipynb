{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting String on Any of Multiple Delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem: YOu need to split a string into fields, but the delimiters arent consistent throughout the string\n",
    "\n",
    "\n",
    "\n",
    "line = 'asdf fjdk; afed, fjek,asdf,foo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'[;,\\s]\\s*',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = re.split(r'(;|,|\\s)\\s*', line)\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = fields[::2]\n",
    "delimiters = fields[1::2] + ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ';', ',', ',', ',', '']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdf fjdk;afed,fjek,asdf,foo'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reform the line using the same delimiters\n",
    "\n",
    "''.join(v+d for v,d in zip(values, delimiters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you dont want the separator characters in the result but still need to use parentheses to group parts of the regular expression pattern, make sure you use a noncapture group, specified as (?:...)\n",
    "\n",
    "\n",
    "\n",
    "re.split(r'(?:,|;|\\s)\\s*', line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching Text at the Start or End of a String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem you need to check the start or end of a strin gfo r secific text patterns such as fileneame extensions, URL schems, and so on.\n",
    "\n",
    "\n",
    "filename = 'spam.txt'\n",
    "filename.endswith('.txt')\n",
    "\n",
    "\n",
    "url = 'http://www.python.org'\n",
    "url.startswith('http')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git', 'README.md', 'chap1.ipynb', '.vscode', '.gitignore', 'chap2.ipynb']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chap1.ipynb', 'chap2.ipynb']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in filenames if name.endswith('.ipynb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(name.endswith('.py') for name in filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "def read_data(name):\n",
    "    if name.startswith(('http:', 'https:','ftp:')):\n",
    "        return urlopen(name).read()\n",
    "    else:\n",
    "        with open(name) as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = ['http', 'ftp']\n",
    "url = 'http://www.python.org'\n",
    "url.startswith(tuple(choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='http:'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One might be inclined to use regular expressions as an alternative. FOr examle\n",
    "\n",
    "import re\n",
    "url = 'http://www.python.org'\n",
    "re.match('https:|http:|frp:', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(5, 10), match='class'>\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This', ' ... ', 'is', ' ', 'a', ' ', 'tes']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from https://docs.python.org/3/howto/regex.html\n",
    "import re\n",
    "p = re.compile(r'\\bclass\\b')\n",
    "print(p.search(\"Fine class\"))  #\\b is a word limiter and matches only if there is the word\n",
    "print(p.search(\"subclass\"))\n",
    "\n",
    "#Also if r was not used then \\b would mean backspace character\n",
    "\n",
    "#Groups\n",
    "\n",
    "p = re.compile('(ab)*') #matches if only ab pattern is there\n",
    "\n",
    "p.match('abababab').span()  #8 patterns found\n",
    "\n",
    "p = re.compile('(a)b')\n",
    "m = p.match('ab')\n",
    "m.group()\n",
    "\n",
    "m.group(0)\n",
    "\n",
    "\n",
    "#subgroups are numberred form left to right from 1 upward. Groups can be nested to determine the number just count he opening parenthesis characters going from left to right\n",
    "\n",
    "\n",
    "p = re.compile('(a(b)c)d') #groups are assigned based on the brackets\n",
    "\n",
    "m = p.match('abcd')\n",
    "m.group(0)\n",
    "m.group(1)\n",
    "m.group(2)   #three gruops will be there\n",
    "\n",
    "\n",
    "#incase we want to know the groups\n",
    "\n",
    "m.group(0,1,2)\n",
    "#also\n",
    "m.groups()\n",
    "\n",
    "#For example the following Re detects dobled words in a stirng\n",
    "\n",
    "p = re.compile(r'\\b(\\w+)\\s+\\1\\b')\n",
    "p.search('Paris in the the spring').group()\n",
    "\n",
    "\n",
    "m = re.match(\"([abc])+\", \"abc\")\n",
    "m.groups()\n",
    "\n",
    "m = re.match(\"(?:[abc])+\", \"abc\")\n",
    "m.groups()\n",
    "\n",
    "#Search for a specific word\n",
    "\n",
    "\n",
    "p = re.compile(r'(?P<word>\\b\\w+\\b)')\n",
    "m = p.search('((( Lots of punctuation)))')\n",
    "m.group('word')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Additonally, you can retrieve named groups as a dictionary with groupdict()\n",
    "\n",
    "\n",
    "m.groupdict()   #shows the group dictionary\n",
    "\n",
    "\n",
    "p = re.compile(r'\\b(?P<word>\\w+)\\s+(?P=word)\\b')\n",
    "p.search('Paris in the the spring').group()\n",
    "\n",
    "\n",
    "\n",
    "p = re.compile(r'\\W+')\n",
    "\n",
    "p.split('This is a test, short and sweet, of split().')\n",
    "\n",
    "\n",
    "\n",
    "#if we specify maxsplit\n",
    "\n",
    "p.split('This is a test, short and sweet, of split().', 3)\n",
    "\n",
    "\n",
    "\n",
    "#incase you also need to separate the delimiters\n",
    "\n",
    "p = re.compile(r'\\W+')\n",
    "p2 = re.compile(r'(\\W+)') #group by words\n",
    "\n",
    "p.split(\"This ... is a test\")   #ignores symbols\n",
    "\n",
    "p2.split(\"This ... is a tes\")  #also takes on white spaces\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "re.split(r'[\\W+]', 'Words, WOrds, WOrds')  #takes on whitespaces only\n",
    "\n",
    "re.split(r'([\\W]+)', 'Words,words,words')\n",
    "\n",
    "\n",
    "#Search and replace\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ee8ddc627afdb3e464b957ff205c0c7ba35df3a73d146152ad7c4b158eb19da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
