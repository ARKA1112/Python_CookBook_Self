{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting String on Any of Multiple Delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Problem: YOu need to split a string into fields, but the delimiters arent consistent throughout the string\n",
    "\n",
    "\n",
    "\n",
    "line = 'asdf fjdk; afed, fjek,asdf,foo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.split(r'[;,\\s]\\s*',line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', ' ', 'fjdk', ';', 'afed', ',', 'fjek', ',', 'asdf', ',', 'foo']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields = re.split(r'(;|,|\\s)\\s*', line)\n",
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = fields[::2]\n",
    "delimiters = fields[1::2] + ['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ', ';', ',', ',', ',', '']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delimiters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asdf fjdk;afed,fjek,asdf,foo'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reform the line using the same delimiters\n",
    "\n",
    "''.join(v+d for v,d in zip(values, delimiters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['asdf', 'fjdk', 'afed', 'fjek', 'asdf', 'foo']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you dont want the separator characters in the result but still need to use parentheses to group parts of the regular expression pattern, make sure you use a noncapture group, specified as (?:...)\n",
    "\n",
    "\n",
    "\n",
    "re.split(r'(?:,|;|\\s)\\s*', line)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching Text at the Start or End of a String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Problem you need to check the start or end of a strin gfo r secific text patterns such as fileneame extensions, URL schems, and so on.\n",
    "\n",
    "\n",
    "filename = 'spam.txt'\n",
    "filename.endswith('.txt')\n",
    "\n",
    "\n",
    "url = 'http://www.python.org'\n",
    "url.startswith('http')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "filenames = os.listdir('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.git', 'README.md', 'chap1.ipynb', '.vscode', '.gitignore', 'chap2.ipynb']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chap1.ipynb', 'chap2.ipynb']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in filenames if name.endswith('.ipynb')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(name.endswith('.py') for name in filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "\n",
    "\n",
    "def read_data(name):\n",
    "    if name.startswith(('http:', 'https:','ftp:')):\n",
    "        return urlopen(name).read()\n",
    "    else:\n",
    "        with open(name) as f:\n",
    "            return f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "choices = ['http', 'ftp']\n",
    "url = 'http://www.python.org'\n",
    "url.startswith(tuple(choices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 5), match='http:'>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#One might be inclined to use regular expressions as an alternative. FOr examle\n",
    "\n",
    "import re\n",
    "url = 'http://www.python.org'\n",
    "re.match('https:|http:|frp:', url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<re.Match object; span=(5, 10), match='class'>\n",
      "None\n",
      "(0, 5)\n",
      "None\n",
      "(0, 5)\n",
      "(2, 7)\n",
      "(0, 32)\n",
      "<html><head><title>Title</title>\n",
      "<html><head><title>Title</title>\n"
     ]
    }
   ],
   "source": [
    "#from https://docs.python.org/3/howto/regex.html\n",
    "import re\n",
    "p = re.compile(r'\\bclass\\b')\n",
    "print(p.search(\"Fine class\"))  #\\b is a word limiter and matches only if there is the word\n",
    "print(p.search(\"subclass\"))\n",
    "\n",
    "#Also if r was not used then \\b would mean backspace character\n",
    "\n",
    "#Groups\n",
    "\n",
    "p = re.compile('(ab)*') #matches if only ab pattern is there\n",
    "\n",
    "p.match('abababab').span()  #8 patterns found\n",
    "\n",
    "p = re.compile('(a)b')\n",
    "m = p.match('ab')\n",
    "m.group()\n",
    "\n",
    "m.group(0)\n",
    "\n",
    "\n",
    "#subgroups are numberred form left to right from 1 upward. Groups can be nested to determine the number just count he opening parenthesis characters going from left to right\n",
    "\n",
    "\n",
    "p = re.compile('(a(b)c)d') #groups are assigned based on the brackets\n",
    "\n",
    "m = p.match('abcd')\n",
    "m.group(0)\n",
    "m.group(1)\n",
    "m.group(2)   #three gruops will be there\n",
    "\n",
    "\n",
    "#incase we want to know the groups\n",
    "\n",
    "m.group(0,1,2)\n",
    "#also\n",
    "m.groups()\n",
    "\n",
    "#For example the following Re detects dobled words in a stirng\n",
    "\n",
    "p = re.compile(r'\\b(\\w+)\\s+\\1\\b')\n",
    "p.search('Paris in the the spring').group()\n",
    "\n",
    "\n",
    "m = re.match(\"([abc])+\", \"abc\")\n",
    "m.groups()\n",
    "\n",
    "m = re.match(\"(?:[abc])+\", \"abc\")\n",
    "m.groups()\n",
    "\n",
    "#Search for a specific word\n",
    "\n",
    "\n",
    "p = re.compile(r'(?P<word>\\b\\w+\\b)')\n",
    "m = p.search('((( Lots of punctuation)))')\n",
    "m.group('word')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Additonally, you can retrieve named groups as a dictionary with groupdict()\n",
    "\n",
    "\n",
    "m.groupdict()   #shows the group dictionary\n",
    "\n",
    "\n",
    "p = re.compile(r'\\b(?P<word>\\w+)\\s+(?P=word)\\b')\n",
    "p.search('Paris in the the spring').group()\n",
    "\n",
    "\n",
    "\n",
    "p = re.compile(r'\\W+')\n",
    "\n",
    "p.split('This is a test, short and sweet, of split().')\n",
    "\n",
    "\n",
    "\n",
    "#if we specify maxsplit\n",
    "\n",
    "p.split('This is a test, short and sweet, of split().', 3)\n",
    "\n",
    "\n",
    "\n",
    "#incase you also need to separate the delimiters\n",
    "\n",
    "p = re.compile(r'\\W+')\n",
    "p2 = re.compile(r'(\\W+)') #group by words\n",
    "\n",
    "p.split(\"This ... is a test\")   #ignores symbols\n",
    "\n",
    "p2.split(\"This ... is a tes\")  #also takes on white spaces\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "re.split(r'[\\W+]', 'Words, WOrds, WOrds')  #takes on whitespaces only\n",
    "\n",
    "re.split(r'([\\W]+)', 'Words,words,words')\n",
    "\n",
    "\n",
    "#Search and replace\n",
    "\n",
    "p = re.compile('(blue|white|red)')\n",
    "p.sub('colour', 'blue socks and red shoes')\n",
    "p.sub('color', 'blue socks and red shoes', count=1)  #only one occurence replaced\n",
    "\n",
    "\n",
    "\n",
    "#subn() works the same but returns a 2 tuple containing the new string value and the number of replacements that were performed\n",
    "\n",
    "p =  re.compile('(blue|white|red)')\n",
    "p.subn('color', 'blue socks and red shoes')\n",
    "\n",
    "\n",
    "\n",
    "#Empty matches are replaced only when thery are not adjacent to a previous empty match\n",
    "\n",
    "p  = re.compile('x*')\n",
    "p.sub('-','abxd')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#The following example the replacement functiontranslates decimals into hexadecimal\n",
    "\n",
    "def hexrepl(match):\n",
    "    \"return the hex string for a decimal number\"\n",
    "    value = int(match.group())\n",
    "    return hex(value)\n",
    "\n",
    "p = re.compile(r'\\d+')\n",
    "p.sub(hexrepl, 'Call 6478 for printing, 987 for user code')\n",
    "\n",
    "\n",
    "\n",
    "#common problems\n",
    "\n",
    "#match() function only checks if the re matches at the beginning of the stirn gwhile search() will scan forward through the string for a match which will start at 0;\n",
    "\n",
    "\n",
    "print(re.match('super', 'superstition').span())  #returns\n",
    "\n",
    "print(re.match('super', 'insuperable'))\n",
    "\n",
    "\n",
    "#on the other hand search() will sacn forward through the stirn greporting the first match if finds\n",
    "\n",
    "print(re.search('super','superstition').span())\n",
    "print(re.search('super', 'insuperable').span())\n",
    "\n",
    "\n",
    "\n",
    "#Greedy versus NonGreedy\n",
    "\n",
    "\n",
    "s = '<html><head><title>Title</title>'\n",
    "len(s)\n",
    "print(re.match('<.*>', s).span())\n",
    "print(re.match('<.*>',s).group())\n",
    "\n",
    "\n",
    "print(re.match('<.*>',s).group())\n",
    "\n",
    "\n",
    "#using re.VERBOSE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http:'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Continuing from the cookbook\n",
    "\n",
    "import re\n",
    "url = 'http://www.python.org'\n",
    "re.match(r'http:|https:|ftp:',url).group()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching Strings Using Shell Wildcard patterns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fnmatch import fnmatch, fnmatchcase\n",
    "\n",
    "fnmatch('foo.txt','*.txt')\n",
    "fnmatch('foo.txt','?oo.txt')\n",
    "fnmatch('Dat45.csv','Dat[0-9]*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Dat1.csv', 'Dat2.csv', 'config.ini', 'foo.py']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[name for name in names if fnmatch(name, 'Dat*.csv')]\n",
    "\n",
    "\n",
    "#Also the case sensitivity is base on the system's underlying filesystem\n",
    "\n",
    "fnmatch('foo.txt','*.TXT')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#if distinction matters then use fnmatchcase\n",
    "\n",
    "fnmatchcase('foo.txt','*.TXT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "addresses = [\n",
    "'5412 N CLARK ST',\n",
    "'1060 W ADDISON ST',\n",
    "'1039 W GRANVILLE AVE',\n",
    "'2122 N CLARK ST',\n",
    "'4802 N BROADWAY',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1060 W ADDISON ST', '1039 W GRANVILLE AVE']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fnmatch import fnmatchcase\n",
    "\n",
    "[addr for addr in addresses if fnmatchcase(addr, '* ST')]\n",
    "\n",
    "[addr for addr in addresses if fnmatchcase(addr, '10[0-9][0-9] W*')]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching and searching for text patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = 'yeah, but no, but yeah, but no, but yeah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text == 'yeah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.startswith('yeah')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.find('no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "#for more complilcated matchinguser regular expressions and the re module. To illstrate the basic mechanics of usin regular expressions\n",
    "\n",
    "\n",
    "text1 = '11/27/2022'\n",
    "text2 = 'Nov 27, 2012'\n",
    "\n",
    "\n",
    "\n",
    "import re\n",
    "if re.match(r'\\d+/\\d+/\\d+', text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('no')\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "#if you are going to perform a lot of matches using the same pattern it ussually pays to precompile the regular expression pattern into a pattern object firest. \n",
    "\n",
    "\n",
    "datapat = re.compile(r'\\d+/\\d+/\\d+')\n",
    "if datapat.match(text1):\n",
    "    print('yes')\n",
    "else:\n",
    "    print('nein')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11/27/2012', '3/13/2013']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Today is 11/27/2012. PyCon starts 3/13/2013.'\n",
    "datapat.findall(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pylatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5ee8ddc627afdb3e464b957ff205c0c7ba35df3a73d146152ad7c4b158eb19da"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
